üìÑ File 1 ‚Äî SPEC-LLM-1-Core.md

–ú–æ–¥—É–ª—å llm (—è–¥—Ä–æ): ConnectionManager, Client (stream), Context, DualContext, Manager + –±–∞–∑–æ–≤–∞—è —Ç–µ–ª–µ–º–µ—Ç—Ä–∏—è

0) –ö–æ–Ω—Ç–µ–∫—Å—Ç

–≠—Ç–æ —è–¥—Ä–æ –º–æ–¥—É–ª—è llm. –¶–µ–ª—å ‚Äî –æ–±–µ—Å–ø–µ—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ –±—ã—Å—Ç—Ä—ã–π –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç LLM —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (dual-context) –∏ –≤—à–∏—Ç—ã–º–∏ —Ç–æ—á–∫–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è:
	‚Ä¢	–≤—Ä–µ–º—è —Ä—É–∫–æ–ø–æ–∂–∞—Ç–∏—è (handshake) –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π,
	‚Ä¢	—Å–µ—Ç–µ–≤—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏ (–¥–æ —Å–µ—Ä–≤–µ—Ä–∞ –∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞),
	‚Ä¢	–≤—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞,
	‚Ä¢	—Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞,
	‚Ä¢	–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞,
	‚Ä¢	–≤—Ä–µ–º—è —Ç—ë–ø–ª–æ–≥–æ handover –º–µ–∂–¥—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏.

–í —ç—Ç–æ–º —Ñ–∞–π–ª–µ —Ä–µ–∞–ª–∏–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –∏ ¬´–ø–µ—Å–æ—á–Ω–∏—á–Ω—ã–µ¬ª —Ä–∞–Ω–Ω–µ—Ä—ã. –¢–µ—Å—Ç—ã –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è ‚Äî –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.

1) –î–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç)

project_root/
‚îú‚îÄ configs/
‚îÇ  ‚îú‚îÄ config.yml            # llm.api_key, models.*, timeouts, dual_context
‚îÇ  ‚îî‚îÄ prompts.yml           # system_prompt, response_format_instruction, summarization_prompt
‚îú‚îÄ infra/
‚îÇ  ‚îî‚îÄ redis_config.py       # —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ –º–æ–¥—É–ª–µ cache —Å–ø—Ä–∏–Ω—Ç–∞
‚îú‚îÄ domain/
‚îÇ  ‚îú‚îÄ models.py             # Role, ConversationMessage, LLMStreamChunk, LLMStructuredResponse
‚îÇ  ‚îî‚îÄ interfaces/
‚îÇ     ‚îî‚îÄ llm.py             # –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã LLM*
‚îî‚îÄ llm/
   ‚îú‚îÄ __init__.py
   ‚îú‚îÄ connection.py         # LLMConnectionManager (httpx AsyncClient + keep-alive)
   ‚îú‚îÄ client.py             # OpenAILLMClient: stream_structured_generate(...)
   ‚îú‚îÄ context.py            # LLMContext: –∏—Å—Ç–æ—Ä–∏—è, build_prompt(), estimate_usage_ratio()
   ‚îú‚îÄ dual_context.py       # DualContextController: warmup/handover
   ‚îî‚îÄ manager.py            # ConversationManager: —Ñ–∞—Å–∞–¥ + —Ñ–æ–Ω–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è/–∫—ç—à

2) –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (runtime)
	‚Ä¢	httpx>=0.27
	‚Ä¢	pydantic>=2.7
	‚Ä¢	tiktoken>=0.7 (–æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤; –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞, –Ω–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –æ—Å—Ç–∞–≤–∏—Ç—å)
	‚Ä¢	PyYAML>=6.0 (—á—Ç–µ–Ω–∏–µ configs/prompts)
	‚Ä¢	redis>=5.0 (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∫—ç—à–∞ ‚Äî –≤ –¥—Ä—É–≥–æ–π –∑–∞–¥–∞—á–µ, –Ω–æ –∏–º–ø–æ—Ä—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –Ω—É–∂–µ–Ω)
	‚Ä¢	python-dotenv>=1.0 (–æ–ø—Ü., –¥–ª—è .env)
	‚Ä¢	stdlib: asyncio, time, typing, dataclasses, contextlib, json, hashlib, logging

3) –ö–æ–Ω—Ç—Ä–∞–∫—Ç—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã/—Ç–∏–ø—ã)

domain/models.py (–º–∏–Ω–∏–º—É–º):

from dataclasses import dataclass
from typing import Optional, Literal, TypedDict, List

Role = Literal["user", "assistant", "system"]

class ConversationMessage(TypedDict):
    role: Role
    content: str

ConversationHistory = List[ConversationMessage]

@dataclass(slots=True)
class LLMStreamChunk:
    text_chunk: str
    is_final_chunk: bool = False
    # first-chunk metadata
    is_safe: Optional[bool] = None
    aggression_score: Optional[int] = None

# –î–ª—è client.stream_structured_generate(...) ‚Äî —Ä–∞–∑—Ä–µ—à—ë–Ω –ª—é–±–æ–π Pydantic BaseModel
# –ü—Ä–∏–º–µ—Ä —Ü–µ–ª–µ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è —Å—Ç—Ä–∏–º–∞:
# class LLMStructuredResponse(BaseModel):
#     internal_thought: Optional[str] = None
#     is_safe: Optional[bool] = True
#     answer: str

domain/interfaces/llm.py (–º–∏–Ω–∏–º—É–º —Å–∏–≥–Ω–∞—Ç—É—Ä):

import abc
import httpx
from typing import AsyncGenerator, Type, List
from pydantic import BaseModel

class LLMConnectionManager(abc.ABC):
    async def get_client(self) -> httpx.AsyncClient: ...
    async def shutdown(self) -> None: ...

class AbstractLLMClient(abc.ABC):
    async def stream_structured_generate(
        self,
        http_client: httpx.AsyncClient,
        full_prompt: str,
        model: str,
        response_model: Type[BaseModel]
    ) -> AsyncGenerator[BaseModel, None]: ...

class AbstractLLMContext(abc.ABC):
    def add_message(self, message) -> None: ...
    def build_prompt(self) -> str: ...
    def build_summary_prompt(self, history) -> str: ...
    def get_history_for_summary(self): ...
    def estimate_usage_ratio(self) -> float: ...

class AbstractConversationManager(abc.ABC):
    async def process_user_turn(self, final_user_text: str) -> AsyncGenerator["LLMStreamChunk", None]: ...
    async def shutdown(self) -> None: ...

4) –†–µ–∞–ª–∏–∑–∞—Ü–∏—è (–∫—Ä–∞—Ç–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)

4.1. llm/connection.py ‚Äî LLMConnectionManager
	‚Ä¢	–î–µ—Ä–∂–∏—Ç –ø—É–ª httpx.AsyncClient —Å (–Ω–∞ –∫–∞–∂–¥—ã–π –∑–≤–æ–Ω–æ–∫ —É –Ω–∞—Å —Å–≤–æ—è —Ü–µ–ø–æ—á–∫–∞ llm –º–æ–¥—É–ª—è, —Ç–æ –µ—Å—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –±—É–¥—É—Ç —Å–¥–µ–ª–∞–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–≤–æ–Ω–∫–∞):
	‚Ä¢	headers={"Authorization": f"Bearer {api_key}"}, timeout=config.llm.http_timeout_sec, http2=True. –ü—Ä–æ–≥—Ä–µ–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–µ–ª–∞—è handshanke –∏ warmup, –ø–æ–º–∏–º–æ —ç—Ç–æ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, —á—Ç–æ–± –º–æ–¥–µ–ª—å –≤—Å–µ–≥–¥–∞ –±—ã–ª–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ. –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥–∞, —Ç–∞–º —É–∫–∞–∑–∞–Ω–æ –≤—Ä–µ–º—è —Ä–∞–∑ –≤ –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞–¥–æ –ø—Ä–æ–≥—Ä–µ–≤–∞—Ç—å –º–æ–¥–µ–ª—å. –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –æ—Ç–¥–∞–≤–∞—Ç—å –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≥—Ä–µ—Ç—ã–º –≥–¥–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —á–∞–Ω–∫. 
	‚Ä¢	–ú–µ—Ç—Ä–∏–∫–∏ (JSON-–ª–æ–≥, logger="llm.conn"):
	‚Ä¢	conn_handshake_start/finish (ms): —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞,
	‚Ä¢	keep_alive_ping_start/finish (ms): –ª—ë–≥–∫–∏–π GET/POST ping (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–π endpoint, –º–æ–∂–Ω–æ /v1/models).
	‚Ä¢	–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π if __name__ == "__main__"::
	‚Ä¢	—á–∏—Ç–∞–µ—Ç .env/configs/config.yml,
	‚Ä¢	—Å–æ–∑–¥–∞—ë—Ç –∏ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç, –ø–µ—á–∞—Ç–∞–µ—Ç –¥–≤–∞ JSON-—Å–æ–±—ã—Ç–∏—è.

4.2. llm/client.py ‚Äî OpenAILLMClient
	‚Ä¢	–ú–µ—Ç–æ–¥ stream_structured_generate(...):
	‚Ä¢	–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ (/v1/chat/completions –∏–ª–∏ /responses ‚Äî –≤—ã–±—Ä–∞—Ç—å –æ–¥–∏–Ω –º–∞—Ä—à—Ä—É—Ç –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å),
	‚Ä¢	–í–∫–ª—é—á–∞–µ—Ç stream=True,
	‚Ä¢	–°—Ç—Ä–∏–º —á–∏—Ç–∞–µ—Ç —á–∞–Ω–∫–∞–º–∏, –Ω–∞ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç:
	‚Ä¢	t_first_token_ms (–æ—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞),
	‚Ä¢	–ø–∞—Ä—Å–∏—Ç –ø–µ—Ä–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏ –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç –≤ –≤—ã–∑—ã–≤–∞—é—â–∏–π –∫–æ–¥ —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—ã–π LLMStreamChunk.
	‚Ä¢	–õ–æ–≥–∏ logger="llm.client":
	‚Ä¢	request_send (ts),
	‚Ä¢	first_token (ms),
	‚Ä¢	chunk (size, seq),
	‚Ä¢	stream_end (total_ms, chunks).
	‚Ä¢	–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π if __name__ == "__main__"::
	‚Ä¢	–º–æ–∫–æ–≤—ã–π –≤—ã–∑–æ–≤ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞): —Å—Ç—Ä–æ–∏—Ç —Ñ–µ–π–∫–æ–≤—ã–π AsyncGenerator –∏–∑ 3-4 —á–∞–Ω–∫–æ–≤, –ø–µ—á–∞—Ç–∞–µ—Ç JSON-—Å–æ–±—ã—Ç–∏—è.

4.3. llm/context.py ‚Äî LLMContext
	‚Ä¢	–•—Ä–∞–Ω–∏—Ç –∏—Å—Ç–æ—Ä–∏—é: List[ConversationMessage].
	‚Ä¢	build_prompt() = system_prompt + –∏—Å—Ç–æ—Ä–∏—è + response_format_instruction.
	‚Ä¢	estimate_usage_ratio():
	‚Ä¢	–ª–∏–±–æ —á–µ—Ä–µ–∑ tiktoken (—Ä–µ–∞–ª—å–Ω–æ),
	‚Ä¢	–ª–∏–±–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Å–∏–º–≤–æ–ª—ã/–ª–∏–º–∏—Ç.
	‚Ä¢	–õ–æ–≥ logger="llm.context": usage_ratio (0..1) –ø—Ä–∏ –∫–∞–∂–¥–æ–º add_message.
	‚Ä¢	–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π if __name__ == "__main__"::
	‚Ä¢	–≥—Ä—É–∑–∏—Ç prompts.yml (—Ñ–µ–π–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–∫), –¥–æ–±–∞–≤–ª—è–µ—Ç 2‚Äì3 —Å–æ–æ–±—â–µ–Ω–∏—è, –ø–µ—á–∞—Ç–∞–µ—Ç prompt –∏ ratio.

4.4. llm/dual_context.py ‚Äî DualContextController
	‚Ä¢	–ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ config.yml: warmup_threshold_ratio, handover_threshold_ratio.
	‚Ä¢	–°–æ—Å—Ç–æ—è–Ω–∏—è: active_context, standby_context, warmup_task.
	‚Ä¢	–°–æ–±—ã—Ç–∏—è (JSON-–ª–æ–≥–∏ logger="llm.dual"):
	‚Ä¢	warmup_start/ready,
	‚Ä¢	handover_perform (ms –æ—Ç warmup_ready –¥–æ handover),
	‚Ä¢	warmup_cancelled.
	‚Ä¢	–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π if __name__ == "__main__"::
	‚Ä¢	—ç–º—É–ª—è—Ü–∏—è —Ä–æ—Å—Ç–∞ usage_ratio ‚Üí –∑–∞–ø—É—Å–∫ warmup ‚Üí —É—Å—Ç–∞–Ω–æ–≤–∫–∞ standby ‚Üí handover.

4.5. llm/manager.py ‚Äî ConversationManager
	‚Ä¢	–°–∫–ª–µ–∏–≤–∞–µ—Ç –≤—Å—ë: connection ‚Üí client ‚Üí dual context ‚Üí context.
	‚Ä¢	process_user_turn(text):
	‚Ä¢	–¥–æ–±–∞–≤–ª—è–µ—Ç user –≤ active_context,
	‚Ä¢	–ø—Ä–æ–≤–µ—Ä—è–µ—Ç usage_ratio ‚Üí –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ warmup_start,
	‚Ä¢	—Å–æ–±–∏—Ä–∞–µ—Ç prompt ‚Üí –≤—ã–∑—ã–≤–∞–µ—Ç client.stream_structured_generate(...),
	‚Ä¢	–Ω–∞ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ –ª–æ–≥–∏—Ä—É–µ—Ç time_to_first_token_ms,
	‚Ä¢	—Å—Ç—Ä–∏–º–∏—Ç LLMStreamChunk –Ω–∞—Ä—É–∂—É,
	‚Ä¢	–ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ —Ç–µ–∫—É—â–∏–π –∞–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É—á–µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–π handover),
	‚Ä¢	–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫ —Å is_final_chunk=True.
	‚Ä¢	–õ–æ–≥–∏ logger="llm.manager":
	‚Ä¢	user_turn_start/finish,
	‚Ä¢	time_to_first_token_ms,
	‚Ä¢	response_total_ms,
	‚Ä¢	context_ratio_before/after,
	‚Ä¢	handover_ms_if_any.
	‚Ä¢	–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π if __name__ == "__main__"::
	‚Ä¢	–º–æ–∫–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω: —Ñ–µ–π–∫–æ–≤—ã–π client (–∏–∑ client.py –ø–µ—Å–æ—á–Ω–∏—Ü—ã), context, dual-context ‚Äî –≤—ã–≤–µ—Å—Ç–∏ 3‚Äì4 —á–∞–Ω–∫–∞ –∏ –º–µ—Ç—Ä–∏–∫–∏.

5) –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏
	‚Ä¢	–í—Å–µ –ø—è—Ç—å —Ñ–∞–π–ª–æ–≤ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –∏ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ (–ø–µ—Å–æ—á–Ω–∏—Ü—ã –Ω–µ –ø–∞–¥–∞—é—Ç).
	‚Ä¢	–õ–æ–≥–∏ —Å—Ç—Ä–æ–≥–æ –≤ JSON-–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
	‚Ä¢	–í client.py —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è time_to_first_token_ms.
	‚Ä¢	–í dual_context.py —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è –≤—Ä–µ–º—è –æ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ standby –¥–æ handover.
	‚Ä¢	–í manager.py –µ—Å—Ç—å –≤—Å–µ —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏.

‚∏ª

üìÑ File 2 ‚Äî SPEC-LLM-2-Manual-Probe.md

–†—É—á–Ω–æ–π ¬´–ø—Ä–æ–±–Ω–∏–∫¬ª —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ LLM: –º–µ—Ç—Ä–∏–∫–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞, —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è, —Å–µ—Ç–µ–≤—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏, handshake

0) –ö–æ–Ω—Ç–µ–∫—Å—Ç

–ù—É–∂–µ–Ω —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑ Orchestrator. –û–Ω –¥–µ–ª–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—É (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π), —Å–æ–±–∏—Ä–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –ø–µ—á–∞—Ç–∞–µ—Ç –ª–æ–≥–∏ –∏ –ø–∏—à–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á—ë—Ç –¥–ª—è –ª—é–¥–µ–π.

1) –î–µ—Ä–µ–≤–æ

project_root/
‚îî‚îÄ llm/
   ‚îî‚îÄ test/
      ‚îî‚îÄ manual_probe_llm.py     # —ç—Ç–æ—Ç —Ñ–∞–π–ª

2) –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
	‚Ä¢	–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–¥ –∏–∑ llm/ —è–¥—Ä–∞ (File 1).
	‚Ä¢	PyYAML, python-dotenv.
	‚Ä¢	.env –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å OPENAI_API_KEY (–∏–ª–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª—é—á).

3) –ß—Ç–æ –∏–∑–º–µ—Ä—è–µ–º
	‚Ä¢	Handshake: –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è httpx.AsyncClient + –ø–µ—Ä–≤—ã–π –ª—ë–≥–∫–∏–π ping. –ê —Ç–∞–∫–∂–µ –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è. 
	‚Ä¢	Network RTT: t_send_request ‚Üí t_socket_written (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ‚Üí t_first_byte (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ time –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ await client.stream(...)).
	‚Ä¢	Time to First Token (TTFT): –æ—Ç request_send –¥–æ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞ (–Ω–µ —Å—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≥—Ä–µ–≤–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω—Ä–∏—è). 
	‚Ä¢	Average total response: –æ—Ç request_send –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–∏–º–∞.
	‚Ä¢	Chunk rate: —á–∞–Ω–∫–æ–≤/—Å–µ–∫.
	‚Ä¢	Context usage: ratio –¥–æ/–ø–æ—Å–ª–µ.
	‚Ä¢	Dual-context event timings: warmup_started ‚Üí warmup_ready ‚Üí handover.
	‚Ä¢	–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞: Markdown-—Ñ–∞–π–ª —Å —Ç–∞–±–ª–∏—Ü–µ–π –∑–Ω–∞—á–µ–Ω–∏–π.

4) –§–æ—Ä–º–∞—Ç –ª–æ–≥–æ–≤ (–ø—Ä–∏–º–µ—Ä)

{"event":"handshake_start","ts":...}
{"event":"handshake_finish","ms":42.1}
{"event":"request_send","model":"gpt-4o-mini","ts":...}
{"event":"first_token","ttft_ms":612.7}
{"event":"chunk","i":1,"bytes":128}
{"event":"stream_end","total_ms":2123.5,"chunks":98}
{"event":"context_usage","before":0.31,"after":0.55}
{"event":"warmup_start","ratio":0.52}
{"event":"warmup_ready","ms":340.4}
{"event":"handover_perform","ms_since_ready":12.9}
{"event":"report_saved","path":"reports/llm_probe_2025-08-09T12-30-00.md"}

5) CLI

python llm/test/manual_probe_llm.py \
  --config configs/config.yml \
  --prompts configs/prompts.yml \
  --model main \
  --text "–ü—Ä–∏–≤–µ—Ç! –î–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞." \
  --repeats 5 \
  --report-dir reports

6) –ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞
	1.	–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª—é—á –∏–∑ .env, –∫–æ–Ω—Ñ–∏–≥–∏ config.yml/prompts.yml.
	2.	–°–æ–∑–¥–∞—ë—Ç LLMConnectionManager ‚Üí –ª–æ–≥–∏—Ä—É–µ—Ç handshake.
	3.	–°–æ–∑–¥–∞—ë—Ç ConversationManager —Å –ø—É—Å—Ç–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π.
	4.	–î–µ–ª–∞–µ—Ç repeats –∑–∞–ø—É—Å–∫–æ–≤:
	‚Ä¢	–¥–æ–±–∞–≤–ª—è–µ—Ç –æ–¥–Ω–æ user —Å–æ–æ–±—â–µ–Ω–∏–µ,
	‚Ä¢	—Å—Ç—Ä–∏–º–∏—Ç –æ—Ç–≤–µ—Ç; –Ω–∞ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç TTFT,
	‚Ä¢	—Å–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —á–∏—Å–ª–æ —á–∞–Ω–∫–æ–≤.
	5.	–°—á–∏—Ç–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ/–º–µ–¥–∏–∞–Ω—É/—Ä95 TTFT –∏ total.
	6.	–ü–∏—à–µ—Ç Markdown-–æ—Ç—á—ë—Ç (—Ç–∞–±–ª–∏—Ü–∞, –∫—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã) –≤ --report-dir.
	7.	–ü–µ—á–∞—Ç–∞–µ—Ç report_saved (JSON-–ª–æ–≥).
	8.	if __name__ == "__main__": ‚Äî –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä —Å argparse, –ø–∞–¥–∞—Ç—å –Ω–µ–ª—å–∑—è (–µ—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–∞ ‚Äî –ø–µ—á–∞—Ç–∞–µ—Ç JSON-–æ—à–∏–±–∫—É –∏ sys.exit(1)).

7) –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏
	‚Ä¢	–°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π, —Å–æ–∑–¥–∞—ë—Ç reports/llm_probe_*.md.
	‚Ä¢	TTFT –∏ total –∑–∞–ø–∏—Å–∞–Ω—ã –∫–∞–∫ p50/p95 + —Å—Ä–µ–¥–Ω–µ–µ.
	‚Ä¢	–õ–æ–≥–∏ —Å—Ç—Ä–æ–≥–æ JSON-–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–µ, –æ—Ç—á—ë—Ç ‚Äî —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º—ã–π Markdown.

‚∏ª

üìÑ File 3 ‚Äî SPEC-LLM-3-Manual-E2E-With-Cache.md

–†—É—á–Ω–æ–π e2e-—Ç–µ—Å—Ç llm c Dual-Context + –∫—ç—à —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π (Redis) + –º–µ—Ç—Ä–∏–∫–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –∞—É–¥–∏–æ-—á–∞–Ω–∫–∞

0) –ö–æ–Ω—Ç–µ–∫—Å—Ç

–≠—Ç–æ –±–æ–µ–≤–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –º–æ–¥—É–ª—è llm, –Ω–æ —Å –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–º –º–æ–¥—É–ª–µ–º cache (Redis). –ú—ã:
	‚Ä¢	–ü—Ä–æ–≥–æ–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —à–∞–≥–∞–º–∏.
	‚Ä¢	–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É Dual-Context (warmup ‚Üí handover).
	‚Ä¢	–ö—ç—à–∏—Ä—É–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (summary:session:<hash>) –∏ –º–µ—Ä—è–µ–º cache hit/miss.
	‚Ä¢	–§–∏–∫—Å–∏—Ä—É–µ–º –≤—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º, —É–∫–ª–∞–¥—ã–≤–∞–µ–º—Å—è –ª–∏ –≤ <800ms –¥–ª—è –¥–µ–º–æ.
	‚Ä¢	–õ–æ–≥–∏—Ä—É–µ–º —Å–µ—Ç–µ–≤—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏, handshake, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á—ë—Ç.

1) –î–µ—Ä–µ–≤–æ

project_root/
‚îú‚îÄ cache/
‚îÇ  ‚îú‚îÄ cache.py                     # RedisCacheManager (–∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ —Å–ø—Ä–∏–Ω—Ç–∞)
‚îÇ  ‚îî‚îÄ test/
‚îÇ     ‚îî‚îÄ manual_test_cache.py      # —É–∂–µ –µ—Å—Ç—å
‚îî‚îÄ llm/
   ‚îî‚îÄ test/
      ‚îî‚îÄ manual_test_llm_agent.py  # —ç—Ç–æ—Ç —Ñ–∞–π–ª

2) –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
	‚Ä¢	–ò–∑ File 1: llm/connection.py, llm/client.py, llm/context.py, llm/dual_context.py, llm/manager.py.
	‚Ä¢	redis>=5.0 (—á–µ—Ä–µ–∑ infra/redis_config.RedisConfig + cache.cache.RedisCacheManager).
	‚Ä¢	PyYAML, python-dotenv.
	‚Ä¢	.env: OPENAI_API_KEY, REDIS_HOST/PORT/DB/PASSWORD.

3) –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º
	1.	TTFT (Time to First Token) ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ.
	2.	–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (end-to-end).
	3.	–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ —à–∞–≥–∞–º.
	4.	Dual-context:
	‚Ä¢	–∫–æ–≥–¥–∞ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª warmup,
	‚Ä¢	–∫–æ–≥–¥–∞ —Å—Ç–∞–ª –≥–æ—Ç–æ–≤ standby,
	‚Ä¢	—Å–∫–æ–ª—å–∫–æ –∑–∞–Ω—è–ª handover.
	5.	–ö—ç—à —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π:
	‚Ä¢	–ü–µ—Ä–≤—ã–π –¥–ª–∏–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥ ‚Üí cache miss (—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∏—Ç—Å—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è),
	‚Ä¢	–ü–æ–≤—Ç–æ—Ä —Ç–æ–≥–æ –∂–µ –¥–∏–∞–ª–æ–≥–∞ ‚Üí cache hit (—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —á–∏—Ç–∞–µ—Ç—Å—è, –≤—Ä–µ–º—è –º–µ–Ω—å—à–µ).
	6.	–°–µ—Ç–µ–≤—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –∏ handshake.
	7.	–≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫: Markdown-–æ—Ç—á—ë—Ç + JSON-—Å—ã—Ä—å—ë.

4) –°—Ü–µ–Ω–∞—Ä–∏–π –¥–∏–∞–ª–æ–≥–∞ (–ø—Ä–∏–º–µ—Ä)
	‚Ä¢	Step 1 (user): ¬´–ü—Ä–∏–≤–µ—Ç! –°–∫–∞–∂–∏ –≤ –¥–≤—É—Ö —Ñ—Ä–∞–∑–∞—Ö, —á–µ–º —Ç—ã –ø–æ–ª–µ–∑–µ–Ω –∫–ª–∏–µ–Ω—Ç–∞–º —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏?¬ª
	‚Ä¢	Step 2 (user): ¬´–ê —Ç–µ–ø–µ—Ä—å –≤ –æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ –æ–±—ä—è—Å–Ω–∏ –≤—ã–≥–æ–¥—ã –≤–µ–∂–ª–∏–≤–æ –∏ –±–µ–∑ –≤–æ–¥—ã.¬ª
	‚Ä¢	Step 3 (user): ¬´–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π –≤–µ—Å—å –¥–∏–∞–ª–æ–≥ —Å–ø–∏—Å–∫–æ–º –∏–∑ 3 –ø—É–Ω–∫—Ç–æ–≤.¬ª
	‚Ä¢	–ü–æ–≤—Ç–æ—Ä–∏—Ç—å Step 3 –µ—â—ë —Ä–∞–∑ (–Ω–æ–≤–∞—è —Å–µ—Å—Å–∏—è –∏–ª–∏ —Ç–∞ –∂–µ —Å–µ—Å—Å–∏—è, —Å–º. –∫–ª—é—á–∏ –∫—ç—à–∞) –¥–ª—è cache hit.

5) CLI

python llm/test/manual_test_llm_agent.py \
  --config configs/config.yml \
  --prompts configs/prompts.yml \
  --session-id demo-123 \
  --repeats 2 \
  --report-dir reports

6) –õ–æ–≥-—Å–æ–±—ã—Ç–∏—è (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
	‚Ä¢	conn_handshake_*
	‚Ä¢	request_send, first_token, stream_end
	‚Ä¢	time_to_first_token_ms, response_total_ms
	‚Ä¢	context_usage (before/after)
	‚Ä¢	warmup_start, warmup_ready, handover_perform
	‚Ä¢	summary_cache_check {key, hit: bool, latency_ms}
	‚Ä¢	summary_cache_save {key, bytes, latency_ms}
	‚Ä¢	report_saved {path}

7) –ö–∞–∫ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á–∏ –∫—ç—à–∞
	‚Ä¢	session_hash = sha1(session_id.encode()).hexdigest()[:16]
	‚Ä¢	–ö–ª—é—á –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π: summary:session:{session_hash}

8) –ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞
	1.	–ü–æ–¥–Ω–∏–º–∞–µ—Ç Redis —á–µ—Ä–µ–∑ infra.redis_config.RedisConfig ‚Üí RedisCacheManager.connect().
	2.	–°–æ–∑–¥–∞—ë—Ç ConversationManager —Å –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–º –∫—ç—à–µ–º.
	3.	–ü—Ä–æ–≥–æ–Ω—è–µ—Ç –¥–∏–∞–ª–æ–≥ –æ–¥–∏–Ω —Ä–∞–∑ (–æ–∂–∏–¥–∞–µ–º—ã–π miss –ø–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏).
	4.	–ü—Ä–æ–≥–æ–Ω—è–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–≥ (–æ–∂–∏–¥–∞–µ–º—ã–π hit).
	5.	–°—á–∏—Ç–∞–µ—Ç p50/p95 –¥–ª—è TTFT –∏ total (–ø–æ –≤—Å–µ–º —à–∞–≥–∞–º).
	6.	–ü–∏—à–µ—Ç —Å–≤–æ–¥–Ω—ã–π Markdown-–æ—Ç—á—ë—Ç (—Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ + –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ –ø–æ–ø–∞–¥–∞–Ω–∏–∏ –≤ —Ü–µ–ª—å <800ms –ø–æ TTFT).
	7.	–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –∫—ç—à –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è LLM.
	8.	if __name__ == "__main__": ‚Äî –ø–æ–ª–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä —Å argparse; –ø—Ä–∏ –æ—à–∏–±–∫–µ Redis/–∫–ª—é—á–∞ ‚Äî –ª–æ–≥–∏—Ä—É–µ—Ç JSON-–æ—à–∏–±–∫—É –∏ –Ω–µ –≤–∞–ª–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å –∂—ë—Å—Ç–∫–æ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–¥ 1).

9) –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏
	‚Ä¢	–°–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞—ë—Ç –¥–≤–∞ —Ñ–∞–π–ª–∞:
	‚Ä¢	reports/llm_agent_YYYYmmdd-HHMM.md (—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á—ë—Ç),
	‚Ä¢	reports/llm_agent_YYYYmmdd-HHMM.json (—Å—ã—Ä–æ–π –¥–∞–º–ø –º–µ—Ç—Ä–∏–∫).
	‚Ä¢	–õ–æ–≥–∏ ‚Äî —Å—Ç—Ä–æ–≥–æ JSON –≤ stdout.
	‚Ä¢	–ù–∞ –≤—Ç–æ—Ä–æ–º –ø—Ä–æ–≥–æn–µ –≤–∏–¥–µ–Ω cache hit –ø–æ –∫–ª—é—á—É —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.
	‚Ä¢	–í –æ—Ç—á—ë—Ç–µ –µ—Å—Ç—å —è–≤–Ω–∞—è —Å—Ç—Ä–æ–∫–∞: TTFT p50: ... ms (—Ü–µ–ª—å < 800 ms) ‚Äî OK/FAIL.

10) –ú–∏–Ω–∏-—Å–∫–µ–ª–µ—Ç –ø–µ—Å–æ—á–Ω–∏—Ü—ã (–≤–Ω—É—Ç—Ä–∏ —Ñ–∞–π–ª–∞)

if __name__ == "__main__":
    # 1) argparse + –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–æ–≤/–∫–ª—é—á–µ–π
    # 2) connect Redis + create ConversationManager
    # 3) run scenario (steps) ‚Üí collect metrics
    # 4) save reports (md + json)
    # 5) close/shutdown
    # –í—Å–µ —à–∞–≥–∏ —Å try/except –∏ JSON-–ª–æ–≥–∞–º–∏
    pass



