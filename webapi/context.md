### **Задача: Модуль `webapi/voice_node` (v1, Демо)**

Этот документ описывает первую версию медийного узла (`voice_node`), отвечающего за обработку голоса в реальном времени с использованием WebRTC-сервера **LiveKit**.

#### **1. Контекст и Цель**

Цель этого модуля — создать минимально жизнеспособный (MVP) голосовой узел, который:
- Принимает аудиопоток от клиента (браузера) через LiveKit.
- Выполняет надежное определение голосовой активности (VAD) и перебиваний (barge-in).
- Взаимодействует с `Orchestrator` (пока используется mock-версия) для получения ответов.
- Отправляет сгенерированный аудио-ответ обратно клиенту.
- Обеспечивает минимальные задержки и предоставляет метрики для анализа производительности.

#### **2. Архитектура и Технологический Стек**

| Компонент | Технология/Библиотека | Назначение |
| :--- | :--- | :--- |
| **Media Server** | **LiveKit** | Управление WebRTC-сессиями, комнатами и медиа-потоками. |
| **Voice Node** | **Python (livekit-agents/rtc)** | Основной сервис: подключается к LiveKit, обрабатывает аудио. |
| **VAD** | **Sierra VAD** (или **WebRTC VAD**) | Определение голоса и тишины в аудиопотоке. |
| **Audio Resampling** | **pysoxr** / **resampy** | Преобразование частоты дискретизации аудио (48 кГц <-> 8 кГц). |
| **Orchestrator** | **Mock-класс** | Имитация логики диалога для демонстрации (возвращает эхо). |

#### **3. Структура Проекта**

```
webapi/
├─ voice_node/
│  ├─ __init__.py
│  ├─ config.py               # Конфигурация из .env, параметры аудио и VAD
│  ├─ livekit_runner.py       # Логика подключения и взаимодействия с LiveKit
│  ├─ audio_io.py             # Функции для ресемплинга и нарезки аудио на фреймы
│  ├─ vad.py                  # Абстракция для VAD-модели
│  ├─ orchestrator_mock.py    # Mock-объект для имитации Orchestrator
│  ├─ pipeline.py             # Основной цикл обработки аудио
│  ├─ metrics.py              # Сбор и логирование метрик (t1-t6)
│  └─ main.py                 # Точка входа для запуска voice_node
└─ static/
   └─ client.html             # Простой HTML-клиент для тестирования
```

#### **4. Поток данных и обработка**

1.  **Вход:** Клиент (браузер) отправляет аудио в комнату LiveKit (Opus, 48 кГц).
2.  **Прием:** `voice_node` подписывается на трек клиента, получает аудио, декодирует его в `float32` (48 кГц) и ресемплирует в **`int16` (8 кГц, моно)**.
3.  **Фрейминг:** Поток нарезается на фреймы по 20 мс (320 байт).
4.  **VAD:** Каждый фрейм анализируется `vad.py` для определения наличия голоса.
    *   При обнаружении начала речи (`speech_started`) — фиксируется метрика `t1`.
    *   При обнаружении конца речи (`speech_ended`) — собранная фраза отправляется в `orchestrator_mock`, фиксируется метрика `t2`.
5.  **Логика (Mock):** `orchestrator_mock` получает аудио-фрагмент и генерирует ответ (для демо — простое эхо или синтетический сигнал).
6.  **Ответ:** `voice_node` получает аудио-ответ (PCM, 8 кГц), ресемплирует его обратно в 48 кГц и публикует как собственный аудиотрек в LiveKit. Клиент, подписанный на этот трек, слышит ответ бота.

#### **5. Barge-in (Перебивание)**

-   Когда `voice_node` публикует ответ бота (`bot_playing == True`), он продолжает анализировать входящий поток от пользователя.
-   Если VAD обнаруживает `speech_started` от пользователя в этот момент, `voice_node` немедленно:
    1.  Вызывает `orchestrator_mock.stop_playback()`.
    2.  Прекращает публикацию своего аудио-трека.
    3.  Логирует событие `barge_in` и переходит в состояние прослушивания пользователя.

#### **6. Запуск и Тестирование**

1.  **Поднять LiveKit:**
    ```bash
    docker compose -f docker-compose.livekit.yml up -d
    ```
2.  **Сгенерировать токен:**
    ```bash
    python scripts/gen_token.py --identity my-user
    ```
3.  **Запустить `voice_node`:**
    ```bash
    # Установить зависимости
    pip install livekit-agents numpy soundfile pysoxr webrtcvad-wheels
    # Запустить сервис
    python -m webapi.voice_node.main
    ```
4.  **Открыть `client.html`:** Вставить сгенерированный токен, подключиться к комнате и начать говорить.

