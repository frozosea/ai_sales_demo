### **Задача: Модуль tts_manager.py (v2, гибридный с менеджером соединений)**

Этот документ описывает финальную, утвержденную спецификацию для модуля TTSManager. Версия 2 вводит отдельный класс для управления WebSocket-соединениями, чтобы гарантировать минимальную задержку при работе с потоковыми ответами от LLM.

#### **1. Контекст и цель модуля (CONTEXT)**

TTSManager является **"голосом"** системы. Его единственная задача — быть высокопроизводительным и отказоустойчивым клиентом для API ElevenLabs. Он предоставляет Orchestrator-у унифицированный интерфейс для генерации речи, автоматически выбирая самый быстрый метод (HTTP Streaming или WebSocket) в зависимости от задачи.

* **Потребители:** Orchestrator является единственным потребителем.  
* **Жизненный цикл:** TTSManager и его зависимости не являются **Singleton**, они создаются оркестратором на каждый новый звонок. Оркестратор создает изолированную цепочку на каждый звонок, включая классы работы с соединениями

#### **2. Архитектура и компоненты**

Модуль будет состоять из двух четко разделенных по ответственности классов.

**2.1. TTSConnectionPool**
- **Назначение:** Управляет пулом соединений для HTTP и WebSocket, поддерживая до 10 одновременных соединений.
- **Функции:**
  - `start()`: Запускает пул соединений.
  - `close()`: Останавливает пул и освобождает все соединения.
  - `get_http_connection(call_id: str)`: Возвращает HTTP соединение для указанного звонка.
  - `get_websocket_connection(call_id: str)`: Возвращает WebSocket соединение для указанного звонка.
  - `release_connection(call_id: str, connection_type: ConnectionType)`: Освобождает соединение.

**2.2. TTSManager**
- **Назначение:** Реализует гибридную логику, выбирая оптимальный способ генерации речи.
- **Функции:**
  - `__init__(cfg: TTSConfig, connection_pool: TTSConnectionPool, call_id: str)`: Инициализирует менеджер с конфигурацией, пулом соединений и идентификатором звонка.
  - `stream_static_text(text: str) -> AsyncGenerator[bytes, None]`: HTTP стриминг для статических фраз.
  - `start_llm_stream() -> Tuple[asyncio.Queue[str], asyncio.Queue[bytes]]`: WebSocket стриминг для LLM ответов.

#### **3. Стратегии минимизации задержки**

1. **Гибридный API:** Orchestrator вызывает `stream_static_text` для всех заранее известных фраз и `start_llm_stream` для ответов, генерируемых LLMManager.
2. **Устранение задержки Handshake:** TTSConnectionPool поддерживает соединения в активном состоянии с помощью keep-alive сообщений.
3. **Оптимальные параметры:** Используются параметры `optimize_streaming_latency=4` для HTTP и `auto_mode=true` для WebSocket.
4. **Быстрые модели:** В конфигурации по умолчанию используется `eleven_turbo_v2` или аналогичная быстрая модель.

#### **3. Детальная спецификация TTSManager (v2)**

**3.1. async stream_static_text(self, text: str)**

* **Логика:** Формирует и отправляет POST запрос на .../stream с параметром optimize_streaming_latency=4. Асинхронно возвращает аудио-чанки.

**3.2. async start_llm_stream(self)**

* **Логика:**  
  1. **Получает "горячее" соединение:** websocket = await self.connection_manager.get_connection().  
  2. Создает две asyncio.Queue: text_input_queue и audio_output_queue.  
  3. Запускает в фоне две задачи: _ws_send_task(websocket, text_input_queue) и _ws_receive_task(websocket, audio_output_queue). **Важно:** задачи теперь принимают готовый объект websocket как аргумент.  
  4. Возвращает (text_input_queue, audio_output_queue).  
* **Логика _ws_send_task и _ws_receive_task:** *Остается прежней*, но теперь они работают с уже установленным соединением, которое им передали. Задача инициализации соединения из них уходит.

#### **4. Стратегии минимизации задержки**

1. **Гибридный API:** Orchestrator вызывает stream_static_text для всех заранее известных фраз (числа, реплики из dialogue_map) и start_llm_stream для ответов, генерируемых LLMManager.  
2. **Устранение задержки Handshake:** WebSocketConnectionManager устанавливает соединение при старте приложения и поддерживает его с помощью keep-alive сообщений. TTSManager всегда получает уже готовое соединение, экономя 100-300 мс на каждом LLM-ответе.  
3. **Оптимальные параметры:** Всегда используются параметры optimize_streaming_latency=4 для HTTP и auto_mode=true для WebSocket.  
4. **Быстрые модели:** В конфигурации по умолчанию используется eleven_turbo_v2 или аналогичная быстрая модель.